{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install gdown\n",
    "# !gdown 1zDCi0nnxjP3so8wPwc5JGIj55lWimFw4\n",
    "\n",
    "# !gdown 1p4cBOvRvSsUYdRdkjo4CPFiBqHyjw_87"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import r2_score, root_mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "import pickle as pk\n",
    "from FS.pso import jfs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Seeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_value = 0\n",
    "\n",
    "# 1. Set the `PYTHONHASHSEED` environment variable at a fixed value\n",
    "import os\n",
    "\n",
    "os.environ[\"PYTHONHASHSEED\"] = str(seed_value)\n",
    "\n",
    "# 3. Set the `numpy` pseudo-random generator at a fixed value\n",
    "np.random.seed(seed_value)\n",
    "np.random.default_rng(seed=seed_value)\n",
    "\n",
    "# 4. Set the `tensorflow` pseudo-random generator at a fixed value\n",
    "tf.random.set_seed(seed_value)\n",
    "\n",
    "# Remove limit on dataframe columns\n",
    "pd.set_option(\"display.max_columns\", None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions\n",
    "\n",
    "# Input a series containing X and y to create a windowed dataset\n",
    "def multi_features_windowed_dataset(series, window_size, horizon, batch_size, shuffle_buffer):\n",
    "    ds = tf.data.Dataset.from_tensor_slices(series)\n",
    "    ds = ds.window(window_size + horizon, shift=1, drop_remainder=True)\n",
    "    ds = ds.flat_map(lambda w: w.batch(window_size + horizon))\n",
    "    ds = ds.shuffle(shuffle_buffer_size)\n",
    "    ds = ds.map(lambda w: (w[:-horizon, :-1], w[-horizon:, -1]))\n",
    "    ds = ds.batch(batch_size).prefetch(1)\n",
    "    return ds\n",
    "\n",
    "# Input a series containing X only to get Kp for the next timestep\n",
    "def forecast_single(model, series, window_size, batch_size=64):\n",
    "    ds = tf.data.Dataset.from_tensor_slices(series)\n",
    "    ds = ds.window(window_size, shift=1, drop_remainder=True)\n",
    "    ds = ds.flat_map(lambda w: w.batch(window_size))\n",
    "    ds = ds.batch(batch_size).prefetch(1)\n",
    "    forecast = model.predict(ds).squeeze()\n",
    "    return forecast"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_table(\"./omni2_all_years.dat\", sep=\"\\s+\",header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./omni2_all_years_v2.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv(\"./omnii data ready finale.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop columns of IDs and other indices\n",
    "df.drop(\n",
    "    [\n",
    "        \"ID for IMF SC\",\n",
    "        \"ID for SW Plasma SC\",\n",
    "        \"DST Index\",\n",
    "        \"AE-index\",\n",
    "        \"Ap-index\",\n",
    "        \"f10.7_index\",\n",
    "        \"AL-index\",\n",
    "        \"AU-index\",\n",
    "    ],\n",
    "    inplace=True,\n",
    "    axis=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert year, day, hour to datetime\n",
    "time = pd.to_datetime(df[\"Year\"] * 1000 + df[\"Day\"], format=\"%Y%j\")\n",
    "time = time + pd.to_timedelta(df.Hour, unit=\"h\")\n",
    "df.index = time\n",
    "\n",
    "# Reduce the number of kp values from 28 to 10\n",
    "df[\"Kp\"] = df[\"Kp*10\"].apply(lambda x: round(x / 10))\n",
    "\n",
    "# Drop the old columns\n",
    "df = df.drop([\"Year\", \"Day\", \"Hour\", \"Kp*10\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # average every 3 rows\n",
    "# df = df.resample(\"3H\").mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chosen time range\n",
    "df = df[(df.index.year > 1975) & (df.index.year < 2023)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "replacement = [\n",
    "    999,\n",
    "    999.9,\n",
    "    9999999.0,\n",
    "    9999.0,\n",
    "    99.99,\n",
    "    9.999,\n",
    "    999.99,\n",
    "    999999.99,\n",
    "    99999.99,\n",
    "    99.9,\n",
    "]\n",
    "# Replace missing values with NaN\n",
    "df.replace(replacement, np.nan, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reference features that were used in some papers\n",
    "# ref_features = [\"Bz,GSM\", \"Proton density\", \"Bulk speed\", \"Field Magnitude Avg\", \"Sigma-B\", \"Kp\"]\n",
    "# df = df[ref_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the distribution of the features\n",
    "# for col in df.columns:\n",
    "#     plt.Figure()\n",
    "#     df[col].plot(figsize=(20, 5))\n",
    "#     plt.title(col)\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interpolate the missing values\n",
    "df.interpolate(method=\"time\", limit_direction=\"both\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation between features\n",
    "# corr_matrix = df.corr()\n",
    "\n",
    "# # Plot the heatmap\n",
    "# plt.figure(figsize=(16, 10))\n",
    "# sns.heatmap(corr_matrix, cmap='coolwarm')\n",
    "# plt.title('Correlation Matrix Heatmap')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# corr_matrix[\"Kp\"].abs().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop some redundant features\n",
    "df.drop([\"By,GSM\", \"Bz,GSM\", \"Field Magnitude Avg\"], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Highest correlation with Kp\n",
    "# df.corrwith(df[\"Kp\"]).abs().sort_values(ascending=False)[:7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# selected_features = df.corrwith(df[\"Kp\"]).abs().sort_values(ascending=False)[:7].index.values\n",
    "# df_sub = df[selected_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross correlation between Kp and other features\n",
    "# lagged_corr = []\n",
    "# for i in range(1, 365):\n",
    "#     lagged_corr.append(df.shift(i).corrwith(df[\"Kp\"]).abs())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross correlation plot\n",
    "# lagged_corr = pd.DataFrame(lagged_corr)\n",
    "# title=\"Cross Correlation with Kp\"\n",
    "# xlabel=\"Lag hours\"\n",
    "# ylabel=\"Correlation with Kp\"\n",
    "# lagged_corr.plot(figsize=(16, 10), title=title, xlabel=xlabel, ylabel=ylabel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross correlation between Kp and a subset of features\n",
    "# lagged_corr = pd.DataFrame(lagged_corr)\n",
    "# title=\"Cross Correlation with Kp\"\n",
    "# xlabel=\"Lag hours\"\n",
    "# ylabel=\"Correlation with Kp\"\n",
    "# lagged_corr[selected_features].plot(figsize=(16, 10), title=title, xlabel=xlabel, ylabel=ylabel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pso_features = [\n",
    "#     \"Magnitude of Average Field vector\",\n",
    "#     \"Bx,GSE\",\n",
    "#     \"Sigma-B\",\n",
    "#     \"Sigma-Bx\",\n",
    "#     \"Sigma-By\",\n",
    "#     \"Sigma-Bz\",\n",
    "#     \"Na/Np\",\n",
    "#     \"Sigma-phi-V\",\n",
    "#     \"Sigma-theta-V\",\n",
    "#     \"PROT Flux  >1 MeV\",\n",
    "#     \"PROT Flux  >2 MeV\",\n",
    "#     \"PROT Flux  >30 MeV\",\n",
    "#     \"PROT Flux  >60 MeV\",\n",
    "#     \"PC(N)\",\n",
    "#     \"Kp\",\n",
    "# ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature indices that were selected by PSO\n",
    "# pso_features = [3, 6, 10, 11, 12, 13, 19, 24, 25, 31, 32, 35, 36, 38, 40]\n",
    "# df = df.iloc[:, pso_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train test split\n",
    "split_year = 2008\n",
    "train = df[df.index.year < split_year]\n",
    "test = df[df.index.year >= split_year]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run PSO\n",
    "# # parameter\n",
    "# k    = 5     # k-value in KNN\n",
    "# N    = 10    # number of particles\n",
    "# T    = 100   # maximum number of iterations\n",
    "# fold = fold = {'xt': train.to_numpy(), 'yt':train[\"Kp\"].to_numpy(), 'xv':test.to_numpy(), 'yv':test[\"Kp\"].to_numpy()}\n",
    "# opts = {'k':k, 'fold':fold, 'N':N, 'T':T}\n",
    "\n",
    "# # perform feature selection\n",
    "# fmdl = jfs(df.to_numpy(), df[\"Kp\"].to_numpy(), opts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pso_features = fmdl['sf']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = df.shape[1]\n",
    "num_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y = train[\"Kp\"]\n",
    "test_y = test[\"Kp\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the data except for Kp\n",
    "scaler = StandardScaler()\n",
    "train[train.columns[:-1]] = scaler.fit_transform(train[train.columns[:-1]])\n",
    "test[test.columns[:-1]] = scaler.transform(test[test.columns[:-1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Duplicate the Kp column for the windowed dataset\n",
    "train_xy = pd.concat([train, train_y], axis=1)\n",
    "test_xy = pd.concat([test, test_y], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run PCA on all features to determine the number of components\n",
    "# n_components = num_features\n",
    "# pca = PCA(n_components=n_components)\n",
    "# pca.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.plot(np.cumsum(pca.explained_variance_ratio_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pca.explained_variance_ratio_[0:30].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit PCA with chosen number of components\n",
    "# pca = PCA(n_components=30)\n",
    "# pca.fit(train)\n",
    "\n",
    "# train = pca.transform(train)\n",
    "# test = pca.transform(test)\n",
    "\n",
    "# train_xy = np.append(train, train_y.values.reshape(-1, 1), axis=1)\n",
    "# test_xy = np.append(test, test_y.values.reshape(-1, 1), axis=1)\n",
    "\n",
    "# num_features = pca.n_components_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters for the dataset and model\n",
    "window_size = 24 # window size in hours\n",
    "horizon = 3 # forecast horizon in hours\n",
    "batch_size = 64\n",
    "shuffle_buffer_size = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create windowed datasets\n",
    "ds = multi_features_windowed_dataset(\n",
    "    train_xy, window_size, horizon, batch_size=batch_size, shuffle_buffer=shuffle_buffer_size\n",
    ")\n",
    "test_ds = multi_features_windowed_dataset(\n",
    "    test_xy, window_size, horizon, batch_size=batch_size, shuffle_buffer=shuffle_buffer_size\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "model = tf.keras.Sequential(\n",
    "    [\n",
    "        tf.keras.layers.GRU(\n",
    "            100,\n",
    "            input_shape=(window_size, num_features),\n",
    "            return_sequences=True,\n",
    "        ),\n",
    "        tf.keras.layers.Dropout(0.5),\n",
    "        tf.keras.layers.GRU(\n",
    "            100,\n",
    "            input_shape=(window_size, num_features),\n",
    "        ),\n",
    "        tf.keras.layers.Dropout(0.5),\n",
    "        tf.keras.layers.Dense(\n",
    "            32,\n",
    "            activation=\"relu\",\n",
    "        ),\n",
    "        tf.keras.layers.Dense(horizon),\n",
    "    ]\n",
    ")\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "model.compile(loss=\"mse\", optimizer=optimizer)\n",
    "history = model.fit(ds, epochs=20, validation_data=test_ds, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot loss\n",
    "plt.plot(history.history[\"loss\"], label=\"train\")\n",
    "plt.plot(history.history[\"val_loss\"], label=\"test\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the model on test data\n",
    "pred = forecast_single(model, test, window_size)\n",
    "pred_discrete = pred.round()\n",
    "pred_discrete = np.clip(pred_discrete, 0, 9)\n",
    "# Remove the last prediction as it does not have a corresponding true value\n",
    "pred_discrete = pred_discrete[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cut the window size from the true values as it does not have a corresponding prediction\n",
    "real = test_y[window_size:]\n",
    "\n",
    "# Binary values to classify storms\n",
    "real_binary = (real < 5).astype(int)\n",
    "pred_binary = (pred_discrete < 5).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot results for 1 horizon value\n",
    "x = test_y.index[window_size:]\n",
    "true_interval = real\n",
    "pred_interval = pred_discrete[:,0]\n",
    "\n",
    "plt.plot(x, true_interval, label=\"True\", color=\"blue\")\n",
    "plt.plot(x, pred_interval, label=\"Prediction\", color=\"red\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metrics\n",
    "r2_scores = []\n",
    "f1_scores = []\n",
    "rmses = []\n",
    "rmses.append(root_mean_squared_error(real, pred_discrete[:, 0]))\n",
    "r2_scores.append(r2_score(real, pred_discrete[:, 0]))\n",
    "f1_scores.append(\n",
    "    classification_report(real_binary, pred_binary[:, 0], output_dict=True)[\"0\"][\n",
    "        \"f1-score\"\n",
    "    ]\n",
    ")\n",
    "# Metrics for multiple horizon values\n",
    "for h in range(1, horizon):\n",
    "    rmses.append(root_mean_squared_error(real[h:], pred_discrete[:-h, h]))\n",
    "    r2_scores.append(r2_score(real[h:], pred_discrete[:-h, h]))\n",
    "    f1_scores.append(\n",
    "        classification_report(real_binary[h:], pred_binary[:-h, h], output_dict=True)[\n",
    "            \"0\"\n",
    "        ][\"f1-score\"]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(rmses)\n",
    "print(r2_scores)\n",
    "print(f1_scores)\n",
    "# Average metrics for all horizon values\n",
    "print(f\"RMSE: {np.mean(rmses)}\")\n",
    "print(f\"R2 Score: {np.mean(r2_scores)}\")\n",
    "print(f\"F1 Score: {np.mean(f1_scores)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.plot(r2_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.plot(f1_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix for 1 horizon value\n",
    "cm = confusion_matrix(real, pred_discrete[:, 0])\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\")\n",
    "\n",
    "# Classification report\n",
    "\n",
    "print(classification_report(real, pred_discrete[:, 0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix for binary classification\n",
    "cm = confusion_matrix(real_binary, pred_binary[:, 0])\n",
    "sns.heatmap(\n",
    "    cm,\n",
    "    annot=True,\n",
    "    fmt=\"d\",\n",
    "    xticklabels=[\"Storm\", \"Safe\"],\n",
    "    yticklabels=[\"Storm\", \"Safe\"],\n",
    ").set(xlabel=\"Predicted\", ylabel=\"Real\")\n",
    "\n",
    "print(classification_report(real_binary, pred_binary[:, 0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For future model usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save(\"./model.keras\")\n",
    "# with open('./pca.pkl', 'wb') as pickle_file:\n",
    "#         pk.dump(pca, pickle_file)\n",
    "# with open('./standard_scaler.pkl', 'wb') as pickle_file:\n",
    "#         pk.dump(scaler, pickle_file)\n",
    "\n",
    "# # returns Kp(np.array), storm(bool)\n",
    "# def forecast(scaler, pca, model, data):\n",
    "#     # (remove these : [\n",
    "#     #     \"ID for IMF SC\",\n",
    "#     #     \"ID for SW Plasma SC\",\n",
    "#     #     \"DST Index\",\n",
    "#     #     \"AE-index\",\n",
    "#     #     \"Ap-index\",\n",
    "#     #     \"f10.7_index\",\n",
    "#     #     \"AL-index\",\n",
    "#     #     \"AU-index\",\n",
    "#     #     \"By,GSM\",\n",
    "#     #     \"Bz,GSM\", \n",
    "#     #     \"Field Magnitude Avg\"\n",
    "#     # ])\n",
    "#     # Average the data to be 3 hourly\n",
    "#     # (locate kp in the data here)\n",
    "#     kp = round(kp/10)\n",
    "#     scaled = scaler.transform(data) # do NOT scale Kp\n",
    "#     pca_scaled = pca.transform(scaled)\n",
    "#     pred = model.predict(pca_scaled)\n",
    "#     pred = pred.round()\n",
    "#     pred = np.clip(pred_discrete, 0, 9)\n",
    "#     storm = (pred >= 5).any()\n",
    "#     return (pred, storm)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
